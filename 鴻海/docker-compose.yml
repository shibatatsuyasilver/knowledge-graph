services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: genai-backend
    environment:
      NEO4J_URI: "bolt://neo4j:7687"
      NEO4J_USER: "neo4j"
      NEO4J_PASSWORD: "password"
      LLM_PROVIDER: "${LLM_PROVIDER:-ollama}"
      OPENAI_BASE_URL: "${OPENAI_BASE_URL:-http://host.docker.internal:8080/v1}"
      OPENAI_API_KEY: "${OPENAI_API_KEY:-}"
      GEMINI_BASE_URL: "${GEMINI_BASE_URL:-https://generativelanguage.googleapis.com/v1beta}"
      GEMINI_API_KEY: "${GEMINI_API_KEY:-}"
      GEMINI_MODEL: "${GEMINI_MODEL:-gemini-3-pro-preview}"
      GEMINI_INPUT_TOKEN_LIMIT: "${GEMINI_INPUT_TOKEN_LIMIT:-1048576}"
      GEMINI_OUTPUT_TOKEN_LIMIT: "${GEMINI_OUTPUT_TOKEN_LIMIT:-65536}"
      OLLAMA_BASE_URL: "${OLLAMA_BASE_URL:-http://host.docker.internal:11434}"
      OLLAMA_MODEL: "${OLLAMA_MODEL:-llama3.2:latest}"
      OLLAMA_THINK: "${OLLAMA_THINK:-false}"
      OLLAMA_THINK_JSON: "${OLLAMA_THINK_JSON:-false}"
      LLM_MODEL: "${LLM_MODEL:-mlx-community/Qwen3-8B-4bit-DWQ-053125}"
      EXTRACTION_MODEL: "${EXTRACTION_MODEL:-sam860/deepseek-r1-0528-qwen3:8b}"
      NL2CYPHER_MODEL: "${NL2CYPHER_MODEL:-ministral-3:14b}"
      LLM_MAX_TOKENS: "${LLM_MAX_TOKENS:-2048}"
      CHUNK_SIZE_MODE: "${CHUNK_SIZE_MODE:-provider}"
      CHUNK_SIZE_TOKENS: "${CHUNK_SIZE_TOKENS:-1048576}"
      CHUNK_MIN_TOKENS: "${CHUNK_MIN_TOKENS:-120}"
      EXTRACTION_TIMEOUT_SECONDS: "900"
      EXTRACTION_NUM_PREDICT: "${EXTRACTION_NUM_PREDICT:-8192}"
      NL2CYPHER_TIMEOUT_SECONDS: "900"
      NL2CYPHER_NUM_PREDICT: "${NL2CYPHER_NUM_PREDICT:-1024}"
      GENERAL_CHAT_TIMEOUT_SECONDS: "900"
      KG_QA_USE_LLM: "${KG_QA_USE_LLM:-1}"
      KG_QA_MODEL: "${KG_QA_MODEL:-}"
      KG_QA_MAX_TOKENS: "${KG_QA_MAX_TOKENS:-1024}"
      KG_QA_TEMPERATURE: "${KG_QA_TEMPERATURE:-0.1}"
      INGEST_JOB_TTL_SECONDS: "${INGEST_JOB_TTL_SECONDS:-3600}"
      KEYWORD_SEARCH_MODE: "${KEYWORD_SEARCH_MODE:-html_only}"
    ports:
      - "8000:8000"
    depends_on:
      - neo4j
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - genai-net

  frontend:
    build:
      context: frontend
      dockerfile: Dockerfile
    container_name: genai-frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - genai-net

  neo4j:
    image: neo4j:5-community
    container_name: genai-neo4j
    environment:
      NEO4J_AUTH: neo4j/password
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
    networks:
      - genai-net
    healthcheck:
        test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider localhost:7474 || exit 1"]
        interval: 10s
        timeout: 5s
        retries: 5

volumes:
  neo4j_data:

networks:
  genai-net:
    driver: bridge
