# Copy to .env.local and fill your local secrets.
# This file is safe to commit; .env.local is ignored.

# Required when using Gemini extraction provider in UI.
GEMINI_API_KEY=REPLACE_WITH_YOUR_GEMINI_API_KEY

# Optional Gemini settings.
GEMINI_MODEL=gemini-3-pro-preview
GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta
GEMINI_TWO_PASS_EXTRACTION=1

# Runtime defaults (optional overrides).
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.2:latest
EXTRACTION_NUM_PREDICT=8192
KG_QA_USE_LLM=1
KG_QA_MODEL=
KG_QA_MAX_TOKENS=1024
KG_QA_TEMPERATURE=0.1
